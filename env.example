# LiteLLM Configuration
# Copy this file to .env and update values

# LiteLLM proxy base URL (OpenAI-compatible endpoint)
LITELLM_BASE_URL=http://localhost:4000/v1

# Optional: API key if LiteLLM requires authentication
# LITELLM_API_KEY=your-api-key-here

# Request timeout in milliseconds (default: 120000 = 2 minutes)
REQUEST_TIMEOUT_MS=120000

# Example for production:
# LITELLM_BASE_URL=https://your-litellm-proxy.com/v1
# LITELLM_API_KEY=sk-xxx

